import ares
import sys,os
import freephil as phil
import ares.import_file
import ares.q_transformation as q_trans
import ares.mask
import ares.power
import ares.integrate
import ares.export
import math
import h5z
import numpy

__all__ = []
__version__ = ares.__version__
prog_short_description = 'Integrates series of frames from SEC-SAXS'

phil_sec_str =  '''
sec {
    sort = True
    .help = Sort the input files by header time. If False, the order as in input list used.
    .type = bool
    
    output {
        prefix = frame
        .help = Prefix of output files
        .type = str
        directory = sec_by_frame
        .help = output directory
        .type = path
        start_frame = 1
        .help = Number of the first frame.
        .type = int
    }
}
    '''
phil_sec = phil.parse(phil_sec_str)

phil_core = phil.parse('''
to_import {
    include scope ares.import_file.phil_core
    }
    
input_files = None
.help = List of input files in the Ares PHIL format (usually generated by ares.import) If provided, the import is ignored
.type = path

''' + phil_sec_str + '''
integrate {
    include scope ares.integrate.phil_core
}

mask {
    include scope ares.mask.phil_core
}

q_transformation {
    include scope ares.q_transformation.phil_core
}

include scope ares.power.phil_job_control
''',process_includes=True)



def integrate_file(header, q_masks, q_bins, start_frame=1, prefix='frame', numdigit=None,  nproc=None, sep=" "):
    """
    Integrates individual frames of the file
    :param header: File header
    :type header: h5z.SaxspointH5
    :param q_masks: Binning masks
    :param prefix: Prefix for the file output
    :param start_frame: Numbering of the first frame
    :param nproc: Number of CPUs to be used
    :param sep: Column separator in the output
    :return:
    """

    if numdigit is None:
        numdigit = int(math.log10(len(header['entry/data/time']))) + 1

    ares.my_print('Reducing file: {}'.format(header.path))
    with h5z.FileH5Z(header.path) as h5f:
        for frame in h5f['entry/data/data'][:]:
            avr, std, num = ares.integrate.integrate_mp(frame, q_masks, nproc)
            ares.export.write_atsas(q_bins, avr, std,
                                    file_name=prefix+str(start_frame).zfill(numdigit)+'.dat',
                                    header=['# {} {}'.format(header.path, str(start_frame).zfill(numdigit))])
            start_frame += 1



def run(params):
    """
    Running function for SEC
    """

    threads, jobs = ares.power.get_cpu_distribution(params.job_control)

    if params.input_files is not None:
        ares.my_print('Reading file headers...')
        files = ares.import_file.ImportFiles(file_phil=params.input_files)
        ares.my_print('Processed {} files.'.format(len(files.files_dict)))
    else:
        ares.my_print('Importing files...')
        files = ares.import_file.ImportFiles(run_phil=params.to_import)
        ares.my_print('Processed {} files.'.format(len(files.files_dict)))
        ares.my_print('Writing list of imported files to {}.'.format(params.to_import.output))
        files.write_groups(params.to_import.output)

    if params.sec.sort:
        files.sort_by_time()

    ares.my_print('Q-transformation...')
    det_qs = [q_trans.transform_detector_radial_q(files.files_dict[gr.file[0].path],
                                                 unit=params.q_transformation.units)
             for gr in files.file_groups]

    ares.my_print('Creating masks...')
    masks = [ares.mask.composite_mask(params.mask, files.files_dict[gr.file[0].path])
            for gr in files.file_groups]

    ares.mask.draw_mask(masks[0],'group1_mask.png')

    if (params.integrate.q_range[0] == 0) and (params.integrate.q_range[1] == 0):
        qmin = None
        qmax = None
    else:
        qmin = min(params.integrate.q_range)
        qmax = max(params.integrate.q_range)

    group_digit = int(math.log10(len(files.file_groups))) + 1
    group_id = 1


    normalize_beam = (params.integrate.beam_normalize.real_space is not None
                        or
                      params.integrate.beam_normalize.q_range is not None)
    if normalize_beam and (params.integrate.beam_normalize.real_space is not None
                        and
                      params.integrate.beam_normalize.q_range is not None):
        raise ares.RuntimeErrorUser('Please provide only one '
                                    'of:\nintegrate.beam_normalize.real_space\nintegrate'
                                    '.beam_normalize.q_range')

    if not normalize_beam and params.mask.beamstop.semitransparent is not None:
        normalize_beam = True
        params.integrate.beam_normalize.real_space = [0, params.mask.beamstop.semitransparent]

    if normalize_beam:
        ares.my_print('Normalization to beam fluctuation will be performed.')

    for mask, det_q, group in zip(masks, det_qs,files.file_groups):
        ares.my_print('Preparing bins...')
        q_val, q_mask = ares.integrate.prepare_bins(det_q,
                                                    qmin,
                                                    qmax,
                                                    params.integrate.bins_number,
                                                    mask)
        if normalize_beam:
            beam_bin_mask = ares.integrate.beam_bin_mask(real_space=numpy.array(params.integrate.beam_normalize.real_space)*0.001,
                                                         q_range=params.integrate.beam_normalize.q_range,
                                                         arrQ=det_q,
                                                         pixel_size=files.files_dict[group.file[0].path].pixel_size[0])
            ares.mask.draw_mask(beam_bin_mask,'beam_mask.png')
            q_mask.append(beam_bin_mask)
            if params.integrate.beam_normalize.scale is None:
                scale, err, num = ares.integrate.integrate(files.files_dict[group.file[0].path].data,[beam_bin_mask])
                params.integrate.beam_normalize.scale =scale

        ares.my_print('Using:\nq_min: {qmin:.3f} {un}^-1\nq_max: {qmax:.2f} {un}^-1\nNo.bins: {bins}'.format(qmin=min(q_val),
                                                                                                             qmax=max(q_val),
                                                                                                             bins=len(q_val),
                                                                                                             un=params.q_transformation.units))

        fi_names = [ fi.path for fi in group.file]
        files_ordered = {key:val for key, val in files.files_dict.items() if key in fi_names}

        start_frames = []
        start_frame = params.sec.output.start_frame
        for fi in files_ordered.keys():
            start_frames.append(start_frame)
            start_frame += len(files_ordered[fi]['entry/data/time'])



        group_prefix = os.path.join(params.sec.output.directory,
                                    params.sec.output.prefix+"_"+str(group_id).zfill(group_digit)+"_")

        if not os.path.isdir(params.sec.output.directory):
            try:
                os.mkdir(params.sec.output.directory)
            except:
                raise ares.RuntimeErrorUser('Path is not a directory: {}'.format(params.sec.output.directory))

        from functools import partial
        integrate_partial = partial(integrate_file, numdigit=int(math.log10(start_frame)) + 1,
                                    prefix=group_prefix,
                                    nproc=threads)
        ares.power.map_mp(integrate_partial,
                          list(files_ordered.values()),
                          [q_mask]*len(files_ordered),
                          [q_val]*len(files_ordered),
                          start_frames,
                          nchunks=jobs)
        ares.my_print("Processed {} frames in group {}".format(start_frame, group_id))

        group_id +=1




class JobSec(ares.Job):
    def __set_meta__(self):
        '''
        Sets various package metadata
        '''

        self._program_short_description = 'Another angular REduction for Saxs'

        self._program_name = os.path.basename(sys.argv[0])
        self._program_version = __version__

    def __worker__(self):
        '''
        The actual programme worker
        :return:
        '''
        run(self.params)

    def __set_system_phil__(self):
        '''
        Settings of CLI arguments. self._parser to be used as argparse.ArgumentParser()
        '''
        self._system_phil = phil_core

    def __argument_processing__(self):
        '''
        Adjustments of raw input arguments. Modifies self._args, if needed

        '''
        pass

    def __help_epilog__(self):
        '''
        Epilog for the help

        '''
        pass

    def __process_unhandled__(self):
        '''
        Process unhandled CLI arguments into self.params

        :return:
        '''
        self.params.to_import.search_string.extend(self.unhandled)

def main(argv=None):
    job = JobSec()
    return job.job_exit


if __name__ == "__main__":
    sys.exit(main())